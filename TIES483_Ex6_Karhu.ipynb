{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "TIES483\n",
    "Anette Karhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 6.1\n",
    "Solve optimization problem \n",
    " $$\n",
    "\\begin{align}\n",
    "\\min \\quad \\log(x_1^2+1)+x_2^4+x_1x_3\\\\\n",
    "\\text{s.t. }\\quad x_1^3-x_2^2\\geq 1\\\\\n",
    " x_1,x_3\\geq 0, \\ x_2\\in\\mathbb R\n",
    "\\end{align}\n",
    "$$ using any method that you have available. Analyze the result you got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.optimize import minimize\n",
    "from scipy import optimize\n",
    "import ad\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function f to be minimized\n",
    "def fun(x):\n",
    "    return math.log(x[0]**2+1)+x[1]**4+x[0]*x[2]\n",
    "\n",
    "# The constraint function \n",
    "def g(x):\n",
    "    return x[0]**3-x[1]**2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate gradient and hessian\n",
    "f_gradient, f_hessian = ad.gh(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6931471805599448\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -4.96705366e-09,  0.00000000e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets do the evaluation with scipy's minimize function to solve the problem:\n",
    "\n",
    "x=[1,0,1]\n",
    "#print('f:n gradientin arvo:',f_gradient(x)) # hessian(x))\n",
    "cons = {'type': 'ineq', 'fun': lambda x:  x[0]**3 - x[1]**2 - 1}\n",
    "bnds = ((0, float(\"inf\")), (float(\"inf\"),float(\"inf\")), (0, float(\"inf\")))\n",
    "#minimoidaan funktio\n",
    "min = minimize(fun, x, method='SLSQP', jac=f_gradient\n",
    "               , options={'ftol': 1e-8, 'disp':True}\n",
    "               , constraints = cons, bounds = bnds )\n",
    "min.x\n",
    "#min.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 680.25515739   -2.18311607 -652.06991066]\n",
      "-443538.1600575206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anette\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:400: RuntimeWarning: Method COBYLA cannot handle bounds.\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\Anette\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: OptimizeWarning: Unknown solver options: ftol\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x=[1,0,1]\n",
    "#print('f:n gradientin arvo:',f_gradient(x)) # hessian(x))\n",
    "cons = {'type': 'ineq', 'fun': lambda x:  x[0]**3 - x[1]**2 - 1}\n",
    "bnds = ((0, float(\"inf\")), (float(\"inf\"),float(\"inf\")), (0, float(\"inf\")))\n",
    "#minimoidaan funktio\n",
    "min = minimize(fun, x, method='COBYLA'\n",
    "               , options={'ftol': 1e-8, 'disp':True}\n",
    "               , constraints = cons, bounds = bnds )\n",
    "print(min.x)\n",
    "print(fun(min.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The optimization problem is feasible and solutions can be found. Minimum point differs from what starting point and optimization method we choose. As the $x_1$ and $x_3$ needs to be greater than or equal to zero, the SLQP gives better solution with the constraints. The function value at minimum point seems to go near 0.0. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 6.2\n",
    "Study multiobjective optimization problem $$\n",
    "\\begin{align}\n",
    "\\min  \\{\\|x-(1,0)\\|^2,\\|x-(0,1)\\|^2\\}\\\\\n",
    "\\text{s.t. }x\\in \\mathbb R^2.\n",
    "\\end{align}\n",
    "$$ Chacterize algebraicly (i.e. give a mathematical formulation) the full set of Pareto optimal solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st value: 0.0  2nd value: 2.0000000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's put both minimuns from the exercise into seperate functions and calculate their eaclidian norms\n",
    "# to be able to manually see their behaviour in different spots.\n",
    "def f(x):\n",
    "    return (np.linalg.norm(((x)-np.array([1,0]))))**2\n",
    "def g(x):\n",
    "    return (np.linalg.norm(((x)-np.array([0,1]))))**2\n",
    "\n",
    "# x to evaluate the norms, such as vectors (0,0), (1,0), (0,1) etc.\n",
    "x=np.array([1,0])\n",
    "print('1st value:',(f(x)),' 2nd value:', g(x))\n",
    "\n",
    "# minimum calculated\n",
    "np.minimum(f(x),g(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a list of x's in range [-10,10] to see how these functions behave at this range.\n",
    "x=[]\n",
    "for i in range(-10,10):\n",
    "    for j in range(-10,10):\n",
    "        x.append([i,j])\n",
    "        #print(x)\n",
    "\n",
    "# Lets create a new list for collecting the first function's values at each x[i,j]\n",
    "list1 = []\n",
    "for i in x:\n",
    "    #print(i)\n",
    "    list1.append((np.linalg.norm(((i)-np.array([1,0]))**2)))\n",
    "#print(list1)\n",
    "    \n",
    "# Let's print the smallest function value we get from first function\n",
    "np.min(list1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Now we look for the second minimized functions behavior at each x[i,j]\n",
    "list2 = []\n",
    "for j in x:\n",
    "    #print(j)\n",
    "    list2.append(np.linalg.norm(((j)-np.array([0,1]))**2))\n",
    "#print(list2)\n",
    "\n",
    "# Let's print the smallest function value we get from the second function\n",
    "np.min(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that with different values either function doesn't get below 0. We try to see wheter the values of x's that give the smallest values for the function are pareto optimal.\n",
    "\n",
    "The following points are now selected as Pareto optimal set:\n",
    "$$\n",
    "PO = \\{x \\in\\mathbb R^2 : x \\in\\mathbb (1,0),(0,1)\\}\n",
    "$$\n",
    "\n",
    "These points give the following results:\n",
    "$$\n",
    "f(1.0) = [(0.0),(2.0)] \\\\\n",
    "f(0.1) = [(2.0),(0.0)] \\\\\n",
    "$$\n",
    "\n",
    "Pareto optimality was given as following:\n",
    "\n",
    "A feasible solution $x_1$ is Pareto optimal to the multiobjective optimization problem, if there does not exist a feasible solution $x_2$, $x_1\\neq x_2$, such that\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "f_i(x_2)\\leq f_i(x_1) \\\\\n",
    "f_j(x_2) < f_j(x_1)\\\\\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Let's try:\n",
    "\n",
    "As we have $x_1=(0,1)$ and there does not exist a feasible solution $x_2$, and $x_1\\neq x_2$ such that: \n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "f_i(x_2)\\leq f_i(x_1) \\\\\n",
    "f_j(x_2) < f_j(x_1)\\\\\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "So the second equation never gets satisfyed and point $x_1=(0,1)$ is pareto optimal.\n",
    "\n",
    "As we have $x_1=(1,0)$ and there does not exist a feasible solution $x_2$, and $x_1\\neq x_2$ such that: \n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "f_i(x_2)\\leq f_i(x_1) \\\\\n",
    "f_j(x_2) < f_j(x_1)\\\\\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "So the second equation never gets satisfyed and point $x_1=(1,0)$ is pareto optimal.\n",
    "\n",
    "We can see that there are also more numbers that can be pareto optimal, that can be described the following way:\n",
    "\n",
    "$$\n",
    "PO = \\{x \\in\\mathbb (x , (1-x)) : x \\in\\mathbb [0,1] \\}\n",
    "$$\n",
    "\n",
    "And we see that this set is pareto optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 6.3\n",
    "Calculate the ideal and nadir vectors for the above two objective problem. You can use any methods available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First we calculate the nadir and ideal for the second problem as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal and nadir for Ex. 6.2, with pay-off table:\n",
    "\n",
    "solutions=\n",
    "$$\n",
    "[(0.0),(2.0)] \\\\\n",
    "[(2.0),(0.0)]\n",
    "$$\n",
    "ideal = $[0.0, 0.0]$\n",
    "nadir = $[2.0, 2.0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate ideal and nadir for the first problem.\n",
    "First if we play around with the function we see that its minimum seems to be at $f(x)=(0.0)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = [0]\n",
    "solutions = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function behaviour one vector a time\n",
    "x=[0,0,1]\n",
    "def calc_ideal(fun):\n",
    "    cons = {'type': 'ineq', 'fun': lambda x:  x[0]**3 - x[1]**2 - 1}\n",
    "    bnds = ((0, float(\"inf\")), (float(\"inf\"),float(\"inf\")), (0, float(\"inf\")))\n",
    "    res = minimize(fun, x, method='SLSQP', jac=f_gradient\n",
    "                       , options={'ftol': 1e-8, 'disp':True}\n",
    "                       , constraints = cons, bounds = bnds )\n",
    "    solutions.append(fun(res.x))\n",
    "    ideal=res.fun\n",
    "    return ideal,solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.1163268039954224e-32\n",
      "            Iterations: 12\n",
      "            Function evaluations: 62\n",
      "            Gradient evaluations: 8\n",
      "ideal is 1.1163268039954224e-32\n"
     ]
    }
   ],
   "source": [
    "ideal, solutions= calc_ideal(fun)\n",
    "print (\"ideal is \"+str(ideal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1163268039954224e-32\n"
     ]
    }
   ],
   "source": [
    "for i in solutions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets generate different x vectors to see different solutions:\n",
    "x_list=[]\n",
    "for i in range(0,2):\n",
    "    for j in range(-1,1):\n",
    "        for k in range(0,2):\n",
    "            x_list.append([i,j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the minimum of funtion with many different x-values\n",
    "def calc_ideal(fun, x_list):\n",
    "    vec = []\n",
    "    solutions = [] \n",
    "    for x in x_list:\n",
    "        print(x)\n",
    "        cons = {'type': 'ineq', 'fun': lambda x:  x[0]**3 - x[1]**2 - 1}\n",
    "        bnds = ((0, float(\"inf\")), (float(\"inf\"),float(\"inf\")), (0, float(\"inf\")))\n",
    "        res = minimize(fun, x, method='SLSQP', jac=f_gradient\n",
    "                       , options={'ftol': 1e-8, 'disp':True}\n",
    "                       , constraints = cons, bounds = bnds )\n",
    "        solutions.append(fun(res.x))\n",
    "        vec.append(x)\n",
    "    return vec,solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, 0]\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 8123.7511651909645\n",
      "            Iterations: 18\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 14\n",
      "[0, -1, 1]\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6962288237346909\n",
      "            Iterations: 17\n",
      "            Function evaluations: 45\n",
      "            Gradient evaluations: 16\n",
      "[0, 0, 0]\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 831.6201167052147\n",
      "            Iterations: 33\n",
      "            Function evaluations: 86\n",
      "            Gradient evaluations: 29\n",
      "[0, 0, 1]\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 1.1163268039954224e-32\n",
      "            Iterations: 12\n",
      "            Function evaluations: 62\n",
      "            Gradient evaluations: 8\n",
      "[1, -1, 0]\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.8175780776050849\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1083\n",
      "            Gradient evaluations: 101\n",
      "[1, -1, 1]\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7968117113952536\n",
      "            Iterations: 3\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 3\n",
      "[1, 0, 0]\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6931471805599453\n",
      "            Iterations: 1\n",
      "            Function evaluations: 1\n",
      "            Gradient evaluations: 1\n",
      "[1, 0, 1]\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.6931471805599448\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n"
     ]
    }
   ],
   "source": [
    "vectors, solutions= calc_ideal(fun, x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8123.7511651909645\n",
      "0.6962288237346909\n",
      "831.6201167052147\n",
      "1.1163268039954224e-32\n",
      "0.8175780776050849\n",
      "0.7968117113952536\n",
      "0.6931471805599453\n",
      "0.6931471805599448\n",
      "[0, -1, 0]\n",
      "[0, -1, 1]\n",
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[1, -1, 0]\n",
      "[1, -1, 1]\n",
      "[1, 0, 0]\n",
      "[1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#print solutions and vestors for ideal and nadir selection\n",
    "for i in solutions:\n",
    "    print(i)\n",
    "for b in vectors:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1163268039954224e-32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(solutions))\n",
    "# The minimum from the solutions \n",
    "np.min(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation with pay-off table method of Nadir vector seeems to be $(0.0, -1.0, 0.0)$, as it gives the highest solution and we want minimum. Ideal vector seems to be $(0.0 , 0.0 , 1.0)$ as in that point the function value is $0.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 6.4:\n",
    "Try to generate a representative set of Pareto optimal solutions using the weighting method for the above two objective problem. Compare this set to the set of Pareto optimal solutions from task 2. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the norm with ideal and nadir for the second problem\n",
    "def f_normalized(x):\n",
    "    z_ideal = [0.0, 0.0]\n",
    "    z_nadir = [2.0, 2.0]\n",
    "    z = (f(x), g(x))\n",
    "    zipped = zip(z, z_ideal, z_nadir)\n",
    "    for item in zipped:\n",
    "        #print(item[0])\n",
    "        normalized = (item[0]-item[1])/(item[2]-item[1])\n",
    "    return normalized\n",
    "\n",
    "x=[1,1]\n",
    "print(f_normalized(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weighted method attempt for the first problem. Doesn't work, seems to be problem with gradient calculation.\n",
    "def weighting_method(f_normalized, weights):\n",
    "    points = []\n",
    "    for weight in weights:\n",
    "        res = minimize(\n",
    "            (weight)*(f_normalized(x))\n",
    "            , [0,1]\n",
    "            , method='SLSQP'\n",
    "            , jac=ad.gh((weight)*(f_normalized(x))))\n",
    "        points.append(res.x)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.11111111  2.22222222  3.33333333  4.44444444  5.55555556\n",
      "  6.66666667  7.77777778  8.88888889 10.        ]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-98d53bec383f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrepr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighting_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_normalized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-3c55acd1b666>\u001b[0m in \u001b[0;36mweighting_method\u001b[1;34m(f_normalized, weights)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SLSQP'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             , jac=ad.gh((weight)*(f_normalized(x))))\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ad\\__init__.py\u001b[0m in \u001b[0;36mgh\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[1;31m# customize the documentation with the input function name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'gradient'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m'The %s of %s, '\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'calculated using automatic\\ndifferentiation.\\n\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0,10, num=10)\n",
    "print(weights)\n",
    "repr = weighting_method(f_normalized,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I wasn't able to get the implementation work. But the pareto optimal solution seems to be at the same points as described in the ex. 6.2 by checking function visualisation from wolfram alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
